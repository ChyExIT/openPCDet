2025-03-16 08:41:08,703   INFO  **********************Start logging**********************
2025-03-16 08:41:08,703   INFO  CUDA_VISIBLE_DEVICES=ALL
2025-03-16 08:41:08,703   INFO  Training with a single process
2025-03-16 08:41:08,704   INFO  cfg_file         cfgs/kitti_models/pointpillar.yaml
2025-03-16 08:41:08,704   INFO  batch_size       4
2025-03-16 08:41:08,704   INFO  epochs           80
2025-03-16 08:41:08,705   INFO  workers          4
2025-03-16 08:41:08,705   INFO  extra_tag        default
2025-03-16 08:41:08,705   INFO  ckpt             None
2025-03-16 08:41:08,705   INFO  pretrained_model None
2025-03-16 08:41:08,706   INFO  launcher         none
2025-03-16 08:41:08,706   INFO  tcp_port         18888
2025-03-16 08:41:08,709   INFO  sync_bn          False
2025-03-16 08:41:08,709   INFO  fix_random_seed  False
2025-03-16 08:41:08,710   INFO  ckpt_save_interval 1
2025-03-16 08:41:08,710   INFO  local_rank       None
2025-03-16 08:41:08,710   INFO  max_ckpt_save_num 30
2025-03-16 08:41:08,710   INFO  merge_all_iters_to_one_epoch False
2025-03-16 08:41:08,711   INFO  set_cfgs         None
2025-03-16 08:41:08,711   INFO  max_waiting_mins 0
2025-03-16 08:41:08,712   INFO  start_epoch      0
2025-03-16 08:41:08,712   INFO  num_epochs_to_eval 0
2025-03-16 08:41:08,712   INFO  save_to_file     False
2025-03-16 08:41:08,712   INFO  use_tqdm_to_record False
2025-03-16 08:41:08,712   INFO  logger_iter_interval 50
2025-03-16 08:41:08,713   INFO  ckpt_save_time_interval 300
2025-03-16 08:41:08,713   INFO  wo_gpu_stat      False
2025-03-16 08:41:08,713   INFO  use_amp          False
2025-03-16 08:41:08,713   INFO  cfg.ROOT_DIR: /mnt/e/Projects/pycharm/zhongkeyuan/OpenPCDet-master
2025-03-16 08:41:08,714   INFO  cfg.LOCAL_RANK: 0
2025-03-16 08:41:08,714   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']
2025-03-16 08:41:08,714   INFO  ----------- DATA_CONFIG -----------
2025-03-16 08:41:08,714   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset
2025-03-16 08:41:08,714   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti
2025-03-16 08:41:08,715   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]
2025-03-16 08:41:08,715   INFO  ----------- DATA_SPLIT -----------
2025-03-16 08:41:08,715   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2025-03-16 08:41:08,716   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2025-03-16 08:41:08,716   INFO  ----------- INFO_PATH -----------
2025-03-16 08:41:08,716   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']
2025-03-16 08:41:08,716   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']
2025-03-16 08:41:08,717   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']
2025-03-16 08:41:08,717   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2025-03-16 08:41:08,717   INFO  ----------- DATA_AUGMENTOR -----------
2025-03-16 08:41:08,717   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2025-03-16 08:41:08,717   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': False, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]
2025-03-16 08:41:08,718   INFO  ----------- POINT_FEATURE_ENCODING -----------
2025-03-16 08:41:08,718   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2025-03-16 08:41:08,718   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2025-03-16 08:41:08,718   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2025-03-16 08:41:08,718   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]
2025-03-16 08:41:08,719   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml
2025-03-16 08:41:08,719   INFO  ----------- MODEL -----------
2025-03-16 08:41:08,719   INFO  cfg.MODEL.NAME: PointPillar
2025-03-16 08:41:08,719   INFO  ----------- VFE -----------
2025-03-16 08:41:08,719   INFO  cfg.MODEL.VFE.NAME: PillarVFE
2025-03-16 08:41:08,720   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False
2025-03-16 08:41:08,720   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True
2025-03-16 08:41:08,720   INFO  cfg.MODEL.VFE.USE_NORM: True
2025-03-16 08:41:08,720   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]
2025-03-16 08:41:08,721   INFO  ----------- MAP_TO_BEV -----------
2025-03-16 08:41:08,721   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter
2025-03-16 08:41:08,721   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64
2025-03-16 08:41:08,721   INFO  ----------- BACKBONE_2D -----------
2025-03-16 08:41:08,722   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone
2025-03-16 08:41:08,722   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]
2025-03-16 08:41:08,722   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]
2025-03-16 08:41:08,722   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]
2025-03-16 08:41:08,722   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]
2025-03-16 08:41:08,723   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]
2025-03-16 08:41:08,723   INFO  ----------- DENSE_HEAD -----------
2025-03-16 08:41:08,723   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle
2025-03-16 08:41:08,723   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2025-03-16 08:41:08,723   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True
2025-03-16 08:41:08,724   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539
2025-03-16 08:41:08,724   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0
2025-03-16 08:41:08,724   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2
2025-03-16 08:41:08,724   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]
2025-03-16 08:41:08,725   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2025-03-16 08:41:08,725   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner
2025-03-16 08:41:08,725   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0
2025-03-16 08:41:08,725   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512
2025-03-16 08:41:08,726   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False
2025-03-16 08:41:08,726   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False
2025-03-16 08:41:08,726   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder
2025-03-16 08:41:08,726   INFO  ----------- LOSS_CONFIG -----------
2025-03-16 08:41:08,727   INFO  ----------- LOSS_WEIGHTS -----------
2025-03-16 08:41:08,727   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2025-03-16 08:41:08,727   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0
2025-03-16 08:41:08,727   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2
2025-03-16 08:41:08,728   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2025-03-16 08:41:08,728   INFO  ----------- POST_PROCESSING -----------
2025-03-16 08:41:08,728   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2025-03-16 08:41:08,728   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2025-03-16 08:41:08,729   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2025-03-16 08:41:08,729   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2025-03-16 08:41:08,729   INFO  ----------- NMS_CONFIG -----------
2025-03-16 08:41:08,729   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2025-03-16 08:41:08,730   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2025-03-16 08:41:08,730   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01
2025-03-16 08:41:08,730   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2025-03-16 08:41:08,730   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2025-03-16 08:41:08,731   INFO  ----------- OPTIMIZATION -----------
2025-03-16 08:41:08,731   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4
2025-03-16 08:41:08,731   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80
2025-03-16 08:41:08,731   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2025-03-16 08:41:08,732   INFO  cfg.OPTIMIZATION.LR: 0.003
2025-03-16 08:41:08,732   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2025-03-16 08:41:08,732   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2025-03-16 08:41:08,732   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2025-03-16 08:41:08,732   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2025-03-16 08:41:08,733   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2025-03-16 08:41:08,733   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2025-03-16 08:41:08,733   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2025-03-16 08:41:08,733   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2025-03-16 08:41:08,733   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2025-03-16 08:41:08,734   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2025-03-16 08:41:08,734   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2025-03-16 08:41:08,734   INFO  cfg.TAG: pointpillar
2025-03-16 08:41:08,734   INFO  cfg.EXP_GROUP_PATH: kitti_models
2025-03-16 08:41:08,747   INFO  ----------- Create dataloader & network & optimizer -----------
2025-03-16 08:41:08,909   INFO  Database filter by min points Car: 14357 => 13532
2025-03-16 08:41:08,909   INFO  Database filter by min points Pedestrian: 2207 => 2168
2025-03-16 08:41:08,910   INFO  Database filter by min points Cyclist: 734 => 705
2025-03-16 08:41:08,920   INFO  Database filter by difficulty Car: 13532 => 10759
2025-03-16 08:41:08,922   INFO  Database filter by difficulty Pedestrian: 2168 => 2075
2025-03-16 08:41:08,923   INFO  Database filter by difficulty Cyclist: 705 => 581
2025-03-16 08:41:08,934   INFO  Loading KITTI dataset
2025-03-16 08:41:09,087   INFO  Total samples for KITTI dataset: 3712
2025-03-16 08:41:11,340   INFO  ==> Loading parameters from checkpoint /mnt/e/Projects/pycharm/zhongkeyuan/OpenPCDet-master/output/kitti_models/pointpillar/default/ckpt/checkpoint_epoch_10.pth to GPU
2025-03-16 08:41:11,879   INFO  ==> Loading optimizer parameters from checkpoint /mnt/e/Projects/pycharm/zhongkeyuan/OpenPCDet-master/output/kitti_models/pointpillar/default/ckpt/checkpoint_epoch_10.pth to GPU
2025-03-16 08:41:11,880   INFO  ==> Done
2025-03-16 08:41:11,881   INFO  ----------- Model PointPillar created, param count: 4834888 -----------
2025-03-16 08:41:11,881   INFO  PointPillar(
  (vfe): PillarVFE(
    (pfn_layers): ModuleList(
      (0): PFNLayer(
        (linear): Linear(in_features=10, out_features=64, bias=False)
        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
  )
  (backbone_3d): None
  (map_to_bev_module): PointPillarScatter()
  (pfe): None
  (backbone_2d): BaseBEVBackbone(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (2): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): Sequential(
        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (dense_head): AnchorHeadSingle(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (dir_loss_func): WeightedCrossEntropyLoss()
    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))
    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (point_head): None
  (roi_head): None
)
2025-03-16 08:41:11,882   INFO  **********************Start training kitti_models/pointpillar(default)**********************
2025-03-16 08:41:14,398   INFO  Train:   11/80 ( 14%) [   0/928 (  0%)]  Loss: 0.4998 (0.500)  LR: 9.000e-04  Time cost: 00:02/36:47 [00:02/42:55:10]  Acc_iter 9281        Data time: 0.75(0.75)  Forward time: 1.63(1.63)  Batch time: 2.38(2.38)
2025-03-16 08:41:20,223   INFO  Train:   11/80 ( 14%) [  19/928 (  2%)]  Loss: 0.5201 (0.522)  LR: 9.022e-04  Time cost: 00:08/06:12 [00:08/7:23:56]  Acc_iter 9300        Data time: 0.02(0.05)  Forward time: 0.29(0.36)  Batch time: 0.30(0.41)
2025-03-16 08:41:20,224   INFO  
2025-03-16 08:41:35,573   INFO  Train:   11/80 ( 14%) [  69/928 (  7%)]  Loss: 0.5301 (0.520)  LR: 9.082e-04  Time cost: 00:23/04:49 [00:23/6:03:54]  Acc_iter 9350        Data time: 0.02(0.03)  Forward time: 0.29(0.31)  Batch time: 0.31(0.34)
2025-03-16 08:41:51,044   INFO  Train:   11/80 ( 14%) [ 119/928 ( 13%)]  Loss: 0.5760 (0.526)  LR: 9.142e-04  Time cost: 00:39/04:23 [00:39/5:51:26]  Acc_iter 9400        Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.33)
2025-03-16 08:42:06,823   INFO  Train:   11/80 ( 14%) [ 169/928 ( 18%)]  Loss: 0.4625 (0.522)  LR: 9.202e-04  Time cost: 00:54/04:04 [00:54/5:48:06]  Acc_iter 9450        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:42:06,825   INFO  
2025-03-16 08:42:22,631   INFO  Train:   11/80 ( 14%) [ 219/928 ( 24%)]  Loss: 0.5183 (0.520)  LR: 9.262e-04  Time cost: 01:10/03:47 [01:10/5:46:19]  Acc_iter 9500        Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:42:38,105   INFO  Train:   11/80 ( 14%) [ 269/928 ( 29%)]  Loss: 0.4717 (0.522)  LR: 9.322e-04  Time cost: 01:26/03:30 [01:26/5:43:45]  Acc_iter 9550        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:42:53,782   INFO  Train:   11/80 ( 14%) [ 319/928 ( 34%)]  Loss: 0.5396 (0.523)  LR: 9.383e-04  Time cost: 01:41/03:13 [01:41/5:42:36]  Acc_iter 9600        Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:42:53,784   INFO  
2025-03-16 08:43:09,424   INFO  Train:   11/80 ( 14%) [ 369/928 ( 40%)]  Loss: 0.7045 (0.524)  LR: 9.444e-04  Time cost: 01:57/02:57 [01:57/5:41:35]  Acc_iter 9650        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:43:25,158   INFO  Train:   11/80 ( 14%) [ 419/928 ( 45%)]  Loss: 0.5596 (0.525)  LR: 9.505e-04  Time cost: 02:13/02:41 [02:13/5:40:59]  Acc_iter 9700        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:43:40,911   INFO  Train:   11/80 ( 14%) [ 469/928 ( 51%)]  Loss: 0.5354 (0.525)  LR: 9.566e-04  Time cost: 02:28/02:25 [02:29/5:40:30]  Acc_iter 9750        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:43:40,913   INFO  
2025-03-16 08:43:56,776   INFO  Train:   11/80 ( 14%) [ 519/928 ( 56%)]  Loss: 0.5388 (0.527)  LR: 9.627e-04  Time cost: 02:44/02:09 [02:44/5:40:17]  Acc_iter 9800        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:44:12,355   INFO  Train:   11/80 ( 14%) [ 569/928 ( 61%)]  Loss: 0.5331 (0.528)  LR: 9.689e-04  Time cost: 03:00/01:53 [03:00/5:39:31]  Acc_iter 9850        Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:44:27,934   INFO  Train:   11/80 ( 14%) [ 619/928 ( 67%)]  Loss: 0.6073 (0.528)  LR: 9.750e-04  Time cost: 03:15/01:37 [03:16/5:38:51]  Acc_iter 9900        Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:44:27,936   INFO  
2025-03-16 08:44:43,735   INFO  Train:   11/80 ( 14%) [ 669/928 ( 72%)]  Loss: 0.4349 (0.528)  LR: 9.812e-04  Time cost: 03:31/01:21 [03:31/5:38:35]  Acc_iter 9950        Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:44:59,561   INFO  Train:   11/80 ( 14%) [ 719/928 ( 77%)]  Loss: 0.5186 (0.527)  LR: 9.874e-04  Time cost: 03:47/01:06 [03:47/5:38:22]  Acc_iter 10000       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:45:15,403   INFO  Train:   11/80 ( 14%) [ 769/928 ( 83%)]  Loss: 0.4732 (0.526)  LR: 9.937e-04  Time cost: 04:03/00:50 [04:03/5:38:09]  Acc_iter 10050       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:45:15,405   INFO  
2025-03-16 08:45:31,239   INFO  Train:   11/80 ( 14%) [ 819/928 ( 88%)]  Loss: 0.4729 (0.525)  LR: 9.999e-04  Time cost: 04:19/00:34 [04:19/5:37:56]  Acc_iter 10100       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:45:47,046   INFO  Train:   11/80 ( 14%) [ 869/928 ( 94%)]  Loss: 0.4711 (0.525)  LR: 1.006e-03  Time cost: 04:35/00:18 [04:35/5:37:40]  Acc_iter 10150       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:46:02,790   INFO  Train:   11/80 ( 14%) [ 919/928 ( 99%)]  Loss: 0.4611 (0.525)  LR: 1.012e-03  Time cost: 04:50/00:02 [04:50/5:37:20]  Acc_iter 10200       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:46:02,791   INFO  
2025-03-16 08:46:05,232   INFO  Train:   11/80 ( 14%) [ 927/928 (100%)]  Loss: 0.6236 (0.525)  LR: 1.013e-03  Time cost: 04:53/00:00 [04:53/5:37:11]  Acc_iter 10208       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:46:06,581   INFO  Train:   12/80 ( 15%) [   0/928 (  0%)]  Loss: 0.4758 (0.476)  LR: 1.014e-03  Time cost: 00:00/13:23 [04:54/15:24:17]  Acc_iter 10209       Data time: 0.48(0.48)  Forward time: 0.37(0.37)  Batch time: 0.85(0.85)
2025-03-16 08:46:19,518   INFO  Train:   12/80 ( 15%) [  41/928 (  4%)]  Loss: 0.5500 (0.519)  LR: 1.019e-03  Time cost: 00:13/04:51 [05:07/5:50:30]  Acc_iter 10250       Data time: 0.02(0.03)  Forward time: 0.29(0.30)  Batch time: 0.31(0.33)
2025-03-16 08:46:35,354   INFO  Train:   12/80 ( 15%) [  91/928 ( 10%)]  Loss: 0.5509 (0.532)  LR: 1.025e-03  Time cost: 00:29/04:29 [05:23/5:43:19]  Acc_iter 10300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:46:51,158   INFO  Train:   12/80 ( 15%) [ 141/928 ( 15%)]  Loss: 0.4621 (0.525)  LR: 1.031e-03  Time cost: 00:45/04:11 [05:39/5:40:46]  Acc_iter 10350       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:46:51,160   INFO  
2025-03-16 08:47:07,047   INFO  Train:   12/80 ( 15%) [ 191/928 ( 21%)]  Loss: 0.5923 (0.527)  LR: 1.038e-03  Time cost: 01:01/03:55 [05:55/5:39:53]  Acc_iter 10400       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:47:22,961   INFO  Train:   12/80 ( 15%) [ 241/928 ( 26%)]  Loss: 0.5459 (0.526)  LR: 1.044e-03  Time cost: 01:17/03:39 [06:11/5:39:21]  Acc_iter 10450       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:47:38,895   INFO  Train:   12/80 ( 15%) [ 291/928 ( 31%)]  Loss: 0.5938 (0.527)  LR: 1.051e-03  Time cost: 01:33/03:23 [06:27/5:39:00]  Acc_iter 10500       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:47:38,897   INFO  
2025-03-16 08:47:54,616   INFO  Train:   12/80 ( 15%) [ 341/928 ( 37%)]  Loss: 0.4622 (0.525)  LR: 1.057e-03  Time cost: 01:48/03:06 [06:42/5:38:00]  Acc_iter 10550       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:48:10,543   INFO  Train:   12/80 ( 15%) [ 391/928 ( 42%)]  Loss: 0.4905 (0.526)  LR: 1.063e-03  Time cost: 02:04/02:51 [06:58/5:37:45]  Acc_iter 10600       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:48:26,609   INFO  Train:   12/80 ( 15%) [ 441/928 ( 48%)]  Loss: 0.5248 (0.526)  LR: 1.070e-03  Time cost: 02:20/02:35 [07:14/5:37:50]  Acc_iter 10650       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:48:26,611   INFO  
2025-03-16 08:48:42,439   INFO  Train:   12/80 ( 15%) [ 491/928 ( 53%)]  Loss: 0.5360 (0.526)  LR: 1.076e-03  Time cost: 02:36/02:19 [07:30/5:37:20]  Acc_iter 10700       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:48:58,194   INFO  Train:   12/80 ( 15%) [ 541/928 ( 58%)]  Loss: 0.5643 (0.525)  LR: 1.083e-03  Time cost: 02:52/02:03 [07:46/5:36:44]  Acc_iter 10750       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:49:13,929   INFO  Train:   12/80 ( 15%) [ 591/928 ( 64%)]  Loss: 0.5729 (0.525)  LR: 1.089e-03  Time cost: 03:08/01:47 [08:02/5:36:09]  Acc_iter 10800       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:49:13,931   INFO  
2025-03-16 08:49:29,626   INFO  Train:   12/80 ( 15%) [ 641/928 ( 69%)]  Loss: 0.5353 (0.525)  LR: 1.096e-03  Time cost: 03:23/01:31 [08:17/5:35:34]  Acc_iter 10850       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:49:45,447   INFO  Train:   12/80 ( 15%) [ 691/928 ( 74%)]  Loss: 0.4780 (0.524)  LR: 1.102e-03  Time cost: 03:39/01:15 [08:33/5:35:12]  Acc_iter 10900       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:50:01,337   INFO  Train:   12/80 ( 15%) [ 741/928 ( 80%)]  Loss: 0.4749 (0.524)  LR: 1.109e-03  Time cost: 03:55/00:59 [08:49/5:34:57]  Acc_iter 10950       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:50:01,338   INFO  
2025-03-16 08:50:17,473   INFO  Train:   12/80 ( 15%) [ 791/928 ( 85%)]  Loss: 0.4948 (0.525)  LR: 1.115e-03  Time cost: 04:11/00:43 [09:05/5:35:02]  Acc_iter 11000       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:50:33,334   INFO  Train:   12/80 ( 15%) [ 841/928 ( 91%)]  Loss: 0.4531 (0.525)  LR: 1.122e-03  Time cost: 04:27/00:27 [09:21/5:34:44]  Acc_iter 11050       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:50:49,143   INFO  Train:   12/80 ( 15%) [ 891/928 ( 96%)]  Loss: 0.5891 (0.525)  LR: 1.128e-03  Time cost: 04:43/00:11 [09:37/5:34:22]  Acc_iter 11100       Data time: 0.02(0.02)  Forward time: 0.34(0.30)  Batch time: 0.36(0.32)
2025-03-16 08:50:49,144   INFO  
2025-03-16 08:51:00,531   INFO  Train:   12/80 ( 15%) [ 927/928 (100%)]  Loss: 0.4688 (0.524)  LR: 1.133e-03  Time cost: 04:54/00:00 [09:48/5:34:07]  Acc_iter 11136       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:51:01,875   INFO  Train:   13/80 ( 16%) [   0/928 (  0%)]  Loss: 0.4835 (0.484)  LR: 1.133e-03  Time cost: 00:00/13:13 [09:49/14:58:48]  Acc_iter 11137       Data time: 0.53(0.53)  Forward time: 0.31(0.31)  Batch time: 0.84(0.84)
2025-03-16 08:51:05,984   INFO  Train:   13/80 ( 16%) [  13/928 (  1%)]  Loss: 0.4186 (0.520)  LR: 1.135e-03  Time cost: 00:04/05:24 [09:54/6:12:49]  Acc_iter 11150       Data time: 0.02(0.05)  Forward time: 0.30(0.30)  Batch time: 0.32(0.35)
2025-03-16 08:51:21,714   INFO  Train:   13/80 ( 16%) [  63/928 (  7%)]  Loss: 0.5728 (0.532)  LR: 1.142e-03  Time cost: 00:20/04:39 [10:09/5:39:43]  Acc_iter 11200       Data time: 0.02(0.03)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:51:37,587   INFO  Train:   13/80 ( 16%) [ 113/928 ( 12%)]  Loss: 0.5590 (0.526)  LR: 1.148e-03  Time cost: 00:36/04:21 [10:25/5:36:45]  Acc_iter 11250       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:51:37,588   INFO  
2025-03-16 08:51:53,566   INFO  Train:   13/80 ( 16%) [ 163/928 ( 18%)]  Loss: 0.4886 (0.521)  LR: 1.155e-03  Time cost: 00:52/04:05 [10:41/5:36:06]  Acc_iter 11300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:52:09,531   INFO  Train:   13/80 ( 16%) [ 213/928 ( 23%)]  Loss: 0.4808 (0.520)  LR: 1.162e-03  Time cost: 01:08/03:48 [10:57/5:35:34]  Acc_iter 11350       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:52:25,260   INFO  Train:   13/80 ( 16%) [ 263/928 ( 28%)]  Loss: 0.6617 (0.522)  LR: 1.168e-03  Time cost: 01:24/03:32 [11:13/5:34:12]  Acc_iter 11400       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:52:25,262   INFO  
2025-03-16 08:52:41,202   INFO  Train:   13/80 ( 16%) [ 313/928 ( 34%)]  Loss: 0.6718 (0.520)  LR: 1.175e-03  Time cost: 01:40/03:16 [11:29/5:33:53]  Acc_iter 11450       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:52:57,024   INFO  Train:   13/80 ( 16%) [ 363/928 ( 39%)]  Loss: 0.5310 (0.522)  LR: 1.182e-03  Time cost: 01:56/03:00 [11:45/5:33:15]  Acc_iter 11500       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:53:12,999   INFO  Train:   13/80 ( 16%) [ 413/928 ( 45%)]  Loss: 0.4562 (0.524)  LR: 1.188e-03  Time cost: 02:11/02:44 [12:01/5:33:05]  Acc_iter 11550       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:53:13,001   INFO  
2025-03-16 08:53:28,779   INFO  Train:   13/80 ( 16%) [ 463/928 ( 50%)]  Loss: 0.5297 (0.524)  LR: 1.195e-03  Time cost: 02:27/02:28 [12:16/5:32:27]  Acc_iter 11600       Data time: 0.02(0.02)  Forward time: 0.35(0.30)  Batch time: 0.37(0.32)
2025-03-16 08:53:44,699   INFO  Train:   13/80 ( 16%) [ 513/928 ( 55%)]  Loss: 0.5122 (0.522)  LR: 1.202e-03  Time cost: 02:43/02:12 [12:32/5:32:11]  Acc_iter 11650       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:54:00,502   INFO  Train:   13/80 ( 16%) [ 563/928 ( 61%)]  Loss: 0.4427 (0.521)  LR: 1.209e-03  Time cost: 02:59/01:56 [12:48/5:31:42]  Acc_iter 11700       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:54:00,503   INFO  
2025-03-16 08:54:16,397   INFO  Train:   13/80 ( 16%) [ 613/928 ( 66%)]  Loss: 0.5016 (0.520)  LR: 1.215e-03  Time cost: 03:15/01:40 [13:04/5:31:24]  Acc_iter 11750       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:54:32,340   INFO  Train:   13/80 ( 16%) [ 663/928 ( 71%)]  Loss: 0.5422 (0.520)  LR: 1.222e-03  Time cost: 03:31/01:24 [13:20/5:31:12]  Acc_iter 11800       Data time: 0.01(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:54:48,307   INFO  Train:   13/80 ( 16%) [ 713/928 ( 77%)]  Loss: 0.5418 (0.519)  LR: 1.229e-03  Time cost: 03:47/01:08 [13:36/5:31:00]  Acc_iter 11850       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:54:48,309   INFO  
2025-03-16 08:55:04,226   INFO  Train:   13/80 ( 16%) [ 763/928 ( 82%)]  Loss: 0.5482 (0.519)  LR: 1.236e-03  Time cost: 04:03/00:52 [13:52/5:30:45]  Acc_iter 11900       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:55:20,047   INFO  Train:   13/80 ( 16%) [ 813/928 ( 88%)]  Loss: 0.5077 (0.520)  LR: 1.242e-03  Time cost: 04:19/00:36 [14:08/5:30:21]  Acc_iter 11950       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:55:36,054   INFO  Train:   13/80 ( 16%) [ 863/928 ( 93%)]  Loss: 0.4906 (0.520)  LR: 1.249e-03  Time cost: 04:35/00:20 [14:24/5:30:12]  Acc_iter 12000       Data time: 0.02(0.02)  Forward time: 0.35(0.30)  Batch time: 0.37(0.32)
2025-03-16 08:55:36,055   INFO  
2025-03-16 08:55:52,150   INFO  Train:   13/80 ( 16%) [ 913/928 ( 98%)]  Loss: 0.5036 (0.520)  LR: 1.256e-03  Time cost: 04:51/00:04 [14:40/5:30:09]  Acc_iter 12050       Data time: 0.02(0.02)  Forward time: 0.33(0.30)  Batch time: 0.35(0.32)
2025-03-16 08:55:56,526   INFO  Train:   13/80 ( 16%) [ 927/928 (100%)]  Loss: 0.5399 (0.520)  LR: 1.258e-03  Time cost: 04:55/00:00 [14:44/5:29:59]  Acc_iter 12064       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:55:57,792   INFO  Train:   14/80 ( 18%) [   0/928 (  0%)]  Loss: 0.4662 (0.466)  LR: 1.258e-03  Time cost: 00:00/12:16 [14:45/13:42:58]  Acc_iter 12065       Data time: 0.48(0.48)  Forward time: 0.30(0.30)  Batch time: 0.78(0.78)
2025-03-16 08:56:09,120   INFO  Train:   14/80 ( 18%) [  35/928 (  4%)]  Loss: 0.5264 (0.523)  LR: 1.263e-03  Time cost: 00:12/05:00 [14:57/5:48:44]  Acc_iter 12100       Data time: 0.02(0.03)  Forward time: 0.33(0.31)  Batch time: 0.35(0.34)
2025-03-16 08:56:25,061   INFO  Train:   14/80 ( 18%) [  85/928 (  9%)]  Loss: 0.5603 (0.525)  LR: 1.270e-03  Time cost: 00:28/04:35 [15:13/5:37:41]  Acc_iter 12150       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.33)
2025-03-16 08:56:25,063   INFO  
2025-03-16 08:56:41,113   INFO  Train:   14/80 ( 18%) [ 135/928 ( 15%)]  Loss: 0.5052 (0.525)  LR: 1.277e-03  Time cost: 00:44/04:17 [15:29/5:35:24]  Acc_iter 12200       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:56:57,044   INFO  Train:   14/80 ( 18%) [ 185/928 ( 20%)]  Loss: 0.5358 (0.523)  LR: 1.283e-03  Time cost: 01:00/03:59 [15:45/5:33:32]  Acc_iter 12250       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 08:57:12,981   INFO  Train:   14/80 ( 18%) [ 235/928 ( 25%)]  Loss: 0.4419 (0.524)  LR: 1.290e-03  Time cost: 01:15/03:43 [16:01/5:32:22]  Acc_iter 12300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:57:12,983   INFO  
2025-03-16 08:57:28,874   INFO  Train:   14/80 ( 18%) [ 285/928 ( 31%)]  Loss: 0.4325 (0.525)  LR: 1.297e-03  Time cost: 01:31/03:26 [16:16/5:31:22]  Acc_iter 12350       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:57:44,620   INFO  Train:   14/80 ( 18%) [ 335/928 ( 36%)]  Loss: 0.4631 (0.524)  LR: 1.304e-03  Time cost: 01:47/03:09 [16:32/5:30:07]  Acc_iter 12400       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:58:00,576   INFO  Train:   14/80 ( 18%) [ 385/928 ( 41%)]  Loss: 0.5074 (0.524)  LR: 1.311e-03  Time cost: 02:03/02:53 [16:48/5:29:42]  Acc_iter 12450       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:58:00,578   INFO  
2025-03-16 08:58:16,429   INFO  Train:   14/80 ( 18%) [ 435/928 ( 47%)]  Loss: 0.5978 (0.524)  LR: 1.318e-03  Time cost: 02:19/02:37 [17:04/5:29:04]  Acc_iter 12500       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 08:58:32,308   INFO  Train:   14/80 ( 18%) [ 485/928 ( 52%)]  Loss: 0.5305 (0.524)  LR: 1.325e-03  Time cost: 02:35/02:21 [17:20/5:28:34]  Acc_iter 12550       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 08:58:48,134   INFO  Train:   14/80 ( 18%) [ 535/928 ( 58%)]  Loss: 0.5400 (0.523)  LR: 1.332e-03  Time cost: 02:51/02:05 [17:36/5:28:01]  Acc_iter 12600       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:58:48,136   INFO  
2025-03-16 08:59:03,830   INFO  Train:   14/80 ( 18%) [ 585/928 ( 63%)]  Loss: 0.6659 (0.523)  LR: 1.339e-03  Time cost: 03:06/01:49 [17:51/5:27:16]  Acc_iter 12650       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 08:59:19,581   INFO  Train:   14/80 ( 18%) [ 635/928 ( 68%)]  Loss: 0.4531 (0.523)  LR: 1.346e-03  Time cost: 03:22/01:33 [18:07/5:26:42]  Acc_iter 12700       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 08:59:35,520   INFO  Train:   14/80 ( 18%) [ 685/928 ( 74%)]  Loss: 0.5177 (0.523)  LR: 1.353e-03  Time cost: 03:38/01:17 [18:23/5:26:27]  Acc_iter 12750       Data time: 0.01(0.02)  Forward time: 0.32(0.30)  Batch time: 0.33(0.32)
2025-03-16 08:59:35,522   INFO  
2025-03-16 08:59:51,339   INFO  Train:   14/80 ( 18%) [ 735/928 ( 79%)]  Loss: 0.5229 (0.522)  LR: 1.360e-03  Time cost: 03:54/01:01 [18:39/5:26:02]  Acc_iter 12800       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:00:07,516   INFO  Train:   14/80 ( 18%) [ 785/928 ( 85%)]  Loss: 0.4583 (0.522)  LR: 1.367e-03  Time cost: 04:10/00:45 [18:55/5:26:06]  Acc_iter 12850       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:00:23,520   INFO  Train:   14/80 ( 18%) [ 835/928 ( 90%)]  Loss: 0.4445 (0.521)  LR: 1.374e-03  Time cost: 04:26/00:29 [19:11/5:25:55]  Acc_iter 12900       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:00:23,522   INFO  
2025-03-16 09:00:39,274   INFO  Train:   14/80 ( 18%) [ 885/928 ( 95%)]  Loss: 0.4658 (0.521)  LR: 1.381e-03  Time cost: 04:42/00:13 [19:27/5:25:27]  Acc_iter 12950       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:00:52,408   INFO  Train:   14/80 ( 18%) [ 927/928 (100%)]  Loss: 0.4890 (0.520)  LR: 1.386e-03  Time cost: 04:55/00:00 [19:40/5:24:57]  Acc_iter 12992       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:00:53,727   INFO  Train:   15/80 ( 19%) [   0/928 (  0%)]  Loss: 0.4600 (0.460)  LR: 1.387e-03  Time cost: 00:00/12:48 [19:41/14:05:47]  Acc_iter 12993       Data time: 0.50(0.50)  Forward time: 0.32(0.32)  Batch time: 0.81(0.81)
2025-03-16 09:00:56,050   INFO  Train:   15/80 ( 19%) [   7/928 (  1%)]  Loss: 0.5559 (0.504)  LR: 1.388e-03  Time cost: 00:03/06:02 [19:44/6:42:07]  Acc_iter 13000       Data time: 0.02(0.07)  Forward time: 0.30(0.32)  Batch time: 0.32(0.39)
2025-03-16 09:01:12,099   INFO  Train:   15/80 ( 19%) [  57/928 (  6%)]  Loss: 0.4346 (0.502)  LR: 1.395e-03  Time cost: 00:19/04:48 [20:00/5:37:37]  Acc_iter 13050       Data time: 0.02(0.03)  Forward time: 0.29(0.31)  Batch time: 0.31(0.33)
2025-03-16 09:01:12,101   INFO  
2025-03-16 09:01:28,018   INFO  Train:   15/80 ( 19%) [ 107/928 ( 12%)]  Loss: 0.5590 (0.508)  LR: 1.402e-03  Time cost: 00:35/04:26 [20:16/5:31:21]  Acc_iter 13100       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.33)
2025-03-16 09:01:43,943   INFO  Train:   15/80 ( 19%) [ 157/928 ( 17%)]  Loss: 0.4652 (0.509)  LR: 1.409e-03  Time cost: 00:51/04:09 [20:32/5:28:56]  Acc_iter 13150       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:01:59,793   INFO  Train:   15/80 ( 19%) [ 207/928 ( 22%)]  Loss: 0.5670 (0.511)  LR: 1.416e-03  Time cost: 01:06/03:51 [20:47/5:27:11]  Acc_iter 13200       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:01:59,795   INFO  
2025-03-16 09:02:15,848   INFO  Train:   15/80 ( 19%) [ 257/928 ( 28%)]  Loss: 0.4545 (0.511)  LR: 1.423e-03  Time cost: 01:22/03:35 [21:03/5:26:49]  Acc_iter 13250       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:02:31,549   INFO  Train:   15/80 ( 19%) [ 307/928 ( 33%)]  Loss: 0.5483 (0.514)  LR: 1.430e-03  Time cost: 01:38/03:18 [21:19/5:25:19]  Acc_iter 13300       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:02:47,414   INFO  Train:   15/80 ( 19%) [ 357/928 ( 38%)]  Loss: 0.5793 (0.516)  LR: 1.437e-03  Time cost: 01:54/03:02 [21:35/5:24:37]  Acc_iter 13350       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:02:47,416   INFO  
2025-03-16 09:03:03,354   INFO  Train:   15/80 ( 19%) [ 407/928 ( 44%)]  Loss: 0.5548 (0.517)  LR: 1.444e-03  Time cost: 02:10/02:46 [21:51/5:24:13]  Acc_iter 13400       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:03:19,235   INFO  Train:   15/80 ( 19%) [ 457/928 ( 49%)]  Loss: 0.4930 (0.516)  LR: 1.451e-03  Time cost: 02:26/02:30 [22:07/5:23:43]  Acc_iter 13450       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:03:35,301   INFO  Train:   15/80 ( 19%) [ 507/928 ( 55%)]  Loss: 0.5121 (0.516)  LR: 1.458e-03  Time cost: 02:42/02:14 [22:23/5:23:38]  Acc_iter 13500       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:03:35,303   INFO  
2025-03-16 09:03:51,169   INFO  Train:   15/80 ( 19%) [ 557/928 ( 60%)]  Loss: 0.5523 (0.516)  LR: 1.465e-03  Time cost: 02:58/01:58 [22:39/5:23:09]  Acc_iter 13550       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:04:07,063   INFO  Train:   15/80 ( 19%) [ 607/928 ( 65%)]  Loss: 0.5669 (0.513)  LR: 1.472e-03  Time cost: 03:14/01:42 [22:55/5:22:45]  Acc_iter 13600       Data time: 0.02(0.02)  Forward time: 0.33(0.30)  Batch time: 0.35(0.32)
2025-03-16 09:04:22,975   INFO  Train:   15/80 ( 19%) [ 657/928 ( 71%)]  Loss: 0.5552 (0.514)  LR: 1.479e-03  Time cost: 03:30/01:26 [23:11/5:22:24]  Acc_iter 13650       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:04:22,977   INFO  
2025-03-16 09:04:38,870   INFO  Train:   15/80 ( 19%) [ 707/928 ( 76%)]  Loss: 0.6117 (0.515)  LR: 1.486e-03  Time cost: 03:45/01:10 [23:26/5:22:02]  Acc_iter 13700       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:04:54,751   INFO  Train:   15/80 ( 19%) [ 757/928 ( 82%)]  Loss: 0.5279 (0.515)  LR: 1.493e-03  Time cost: 04:01/00:54 [23:42/5:21:40]  Acc_iter 13750       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:05:10,566   INFO  Train:   15/80 ( 19%) [ 807/928 ( 87%)]  Loss: 0.6469 (0.515)  LR: 1.500e-03  Time cost: 04:17/00:38 [23:58/5:21:14]  Acc_iter 13800       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:05:10,568   INFO  
2025-03-16 09:05:26,424   INFO  Train:   15/80 ( 19%) [ 857/928 ( 92%)]  Loss: 0.4568 (0.516)  LR: 1.508e-03  Time cost: 04:33/00:22 [24:14/5:20:52]  Acc_iter 13850       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:05:42,107   INFO  Train:   15/80 ( 19%) [ 907/928 ( 98%)]  Loss: 0.4393 (0.516)  LR: 1.515e-03  Time cost: 04:49/00:06 [24:30/5:20:19]  Acc_iter 13900       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:05:48,349   INFO  Train:   15/80 ( 19%) [ 927/928 (100%)]  Loss: 0.5229 (0.516)  LR: 1.518e-03  Time cost: 04:55/00:00 [24:36/5:20:04]  Acc_iter 13920       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:05:49,654   INFO  Train:   16/80 ( 20%) [   0/928 (  0%)]  Loss: 0.5137 (0.514)  LR: 1.518e-03  Time cost: 00:00/12:47 [24:37/13:51:08]  Acc_iter 13921       Data time: 0.48(0.48)  Forward time: 0.33(0.33)  Batch time: 0.81(0.81)
2025-03-16 09:05:58,970   INFO  Train:   16/80 ( 20%) [  29/928 (  3%)]  Loss: 0.4964 (0.525)  LR: 1.522e-03  Time cost: 00:10/05:03 [24:47/5:39:42]  Acc_iter 13950       Data time: 0.02(0.03)  Forward time: 0.29(0.30)  Batch time: 0.31(0.34)
2025-03-16 09:05:58,972   INFO  
2025-03-16 09:06:14,910   INFO  Train:   16/80 ( 20%) [  79/928 (  9%)]  Loss: 0.4959 (0.519)  LR: 1.529e-03  Time cost: 00:26/04:36 [25:03/5:27:20]  Acc_iter 14000       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.33)
2025-03-16 09:06:30,749   INFO  Train:   16/80 ( 20%) [ 129/928 ( 14%)]  Loss: 0.5007 (0.516)  LR: 1.536e-03  Time cost: 00:41/04:17 [25:18/5:23:29]  Acc_iter 14050       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:06:46,472   INFO  Train:   16/80 ( 20%) [ 179/928 ( 19%)]  Loss: 0.5213 (0.515)  LR: 1.543e-03  Time cost: 00:57/03:59 [25:34/5:21:00]  Acc_iter 14100       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:06:46,474   INFO  
2025-03-16 09:07:02,334   INFO  Train:   16/80 ( 20%) [ 229/928 ( 25%)]  Loss: 0.6505 (0.516)  LR: 1.550e-03  Time cost: 01:13/03:43 [25:50/5:20:04]  Acc_iter 14150       Data time: 0.01(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:07:18,217   INFO  Train:   16/80 ( 20%) [ 279/928 ( 30%)]  Loss: 0.4095 (0.517)  LR: 1.557e-03  Time cost: 01:29/03:27 [26:06/5:19:28]  Acc_iter 14200       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:07:34,264   INFO  Train:   16/80 ( 20%) [ 329/928 ( 35%)]  Loss: 0.4903 (0.517)  LR: 1.565e-03  Time cost: 01:45/03:11 [26:22/5:19:27]  Acc_iter 14250       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:07:34,267   INFO  
2025-03-16 09:07:50,518   INFO  Train:   16/80 ( 20%) [ 379/928 ( 41%)]  Loss: 0.4927 (0.517)  LR: 1.572e-03  Time cost: 02:01/02:55 [26:38/5:19:55]  Acc_iter 14300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:08:06,445   INFO  Train:   16/80 ( 20%) [ 429/928 ( 46%)]  Loss: 0.5180 (0.519)  LR: 1.579e-03  Time cost: 02:17/02:39 [26:54/5:19:27]  Acc_iter 14350       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:08:22,383   INFO  Train:   16/80 ( 20%) [ 479/928 ( 52%)]  Loss: 0.5042 (0.519)  LR: 1.586e-03  Time cost: 02:33/02:23 [27:10/5:19:03]  Acc_iter 14400       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:08:22,385   INFO  
2025-03-16 09:08:38,324   INFO  Train:   16/80 ( 20%) [ 529/928 ( 57%)]  Loss: 0.4844 (0.518)  LR: 1.593e-03  Time cost: 02:49/02:07 [27:26/5:18:41]  Acc_iter 14450       Data time: 0.01(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:08:54,149   INFO  Train:   16/80 ( 20%) [ 579/928 ( 62%)]  Loss: 0.5227 (0.517)  LR: 1.600e-03  Time cost: 03:05/01:51 [27:42/5:18:08]  Acc_iter 14500       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:09:09,969   INFO  Train:   16/80 ( 20%) [ 629/928 ( 68%)]  Loss: 0.4779 (0.517)  LR: 1.607e-03  Time cost: 03:21/01:35 [27:58/5:17:37]  Acc_iter 14550       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:09:09,971   INFO  
2025-03-16 09:09:25,929   INFO  Train:   16/80 ( 20%) [ 679/928 ( 73%)]  Loss: 0.4866 (0.516)  LR: 1.614e-03  Time cost: 03:37/01:19 [28:14/5:17:21]  Acc_iter 14600       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:09:41,828   INFO  Train:   16/80 ( 20%) [ 729/928 ( 79%)]  Loss: 0.4519 (0.517)  LR: 1.622e-03  Time cost: 03:53/01:03 [28:29/5:17:00]  Acc_iter 14650       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:09:57,727   INFO  Train:   16/80 ( 20%) [ 779/928 ( 84%)]  Loss: 0.5075 (0.517)  LR: 1.629e-03  Time cost: 04:08/00:47 [28:45/5:16:39]  Acc_iter 14700       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:09:57,729   INFO  
2025-03-16 09:10:13,638   INFO  Train:   16/80 ( 20%) [ 829/928 ( 89%)]  Loss: 0.4651 (0.517)  LR: 1.636e-03  Time cost: 04:24/00:31 [29:01/5:16:20]  Acc_iter 14750       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:10:29,740   INFO  Train:   16/80 ( 20%) [ 879/928 ( 95%)]  Loss: 0.5006 (0.517)  LR: 1.643e-03  Time cost: 04:40/00:15 [29:17/5:16:14]  Acc_iter 14800       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:10:44,879   INFO  Train:   16/80 ( 20%) [ 927/928 (100%)]  Loss: 0.5125 (0.517)  LR: 1.650e-03  Time cost: 04:56/00:00 [29:32/5:15:47]  Acc_iter 14848       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:10:46,220   INFO  Train:   17/80 ( 21%) [   0/928 (  0%)]  Loss: 0.4921 (0.492)  LR: 1.650e-03  Time cost: 00:00/13:03 [29:34/13:55:45]  Acc_iter 14849       Data time: 0.48(0.48)  Forward time: 0.35(0.35)  Batch time: 0.83(0.83)
2025-03-16 09:10:46,544   INFO  Train:   17/80 ( 21%) [   1/928 (  0%)]  Loss: 0.5511 (0.522)  LR: 1.650e-03  Time cost: 00:01/09:01 [29:34/9:38:16]  Acc_iter 14850       Data time: 0.02(0.25)  Forward time: 0.32(0.34)  Batch time: 0.34(0.58)
2025-03-16 09:10:46,546   INFO  
2025-03-16 09:11:02,484   INFO  Train:   17/80 ( 21%) [  51/928 (  5%)]  Loss: 0.4946 (0.516)  LR: 1.657e-03  Time cost: 00:17/04:48 [29:50/5:25:23]  Acc_iter 14900       Data time: 0.02(0.03)  Forward time: 0.30(0.30)  Batch time: 0.31(0.33)
2025-03-16 09:11:18,572   INFO  Train:   17/80 ( 21%) [ 101/928 ( 11%)]  Loss: 0.4470 (0.520)  LR: 1.664e-03  Time cost: 00:33/04:29 [30:06/5:21:36]  Acc_iter 14950       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.33)
2025-03-16 09:11:34,514   INFO  Train:   17/80 ( 21%) [ 151/928 ( 16%)]  Loss: 0.4939 (0.518)  LR: 1.672e-03  Time cost: 00:49/04:11 [30:22/5:19:11]  Acc_iter 15000       Data time: 0.01(0.02)  Forward time: 0.30(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:11:34,515   INFO  
2025-03-16 09:11:50,615   INFO  Train:   17/80 ( 21%) [ 201/928 ( 22%)]  Loss: 0.4952 (0.514)  LR: 1.679e-03  Time cost: 01:05/03:54 [30:38/5:18:36]  Acc_iter 15050       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:12:06,556   INFO  Train:   17/80 ( 21%) [ 251/928 ( 27%)]  Loss: 0.4812 (0.513)  LR: 1.686e-03  Time cost: 01:21/03:38 [30:54/5:17:31]  Acc_iter 15100       Data time: 0.02(0.02)  Forward time: 0.31(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:12:22,451   INFO  Train:   17/80 ( 21%) [ 301/928 ( 32%)]  Loss: 0.4801 (0.513)  LR: 1.693e-03  Time cost: 01:37/03:21 [31:10/5:16:34]  Acc_iter 15150       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:12:22,453   INFO  
2025-03-16 09:12:38,404   INFO  Train:   17/80 ( 21%) [ 351/928 ( 38%)]  Loss: 0.4276 (0.512)  LR: 1.700e-03  Time cost: 01:53/03:05 [31:26/5:15:58]  Acc_iter 15200       Data time: 0.01(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:12:54,887   INFO  Train:   17/80 ( 21%) [ 401/928 ( 43%)]  Loss: 0.4550 (0.513)  LR: 1.707e-03  Time cost: 02:09/02:49 [31:43/5:16:44]  Acc_iter 15250       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:13:10,848   INFO  Train:   17/80 ( 21%) [ 451/928 ( 49%)]  Loss: 0.5293 (0.514)  LR: 1.714e-03  Time cost: 02:25/02:33 [31:58/5:16:09]  Acc_iter 15300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:13:10,850   INFO  
2025-03-16 09:13:26,717   INFO  Train:   17/80 ( 21%) [ 501/928 ( 54%)]  Loss: 0.4864 (0.514)  LR: 1.722e-03  Time cost: 02:41/02:17 [32:14/5:15:27]  Acc_iter 15350       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:13:42,593   INFO  Train:   17/80 ( 21%) [ 551/928 ( 59%)]  Loss: 0.5465 (0.515)  LR: 1.729e-03  Time cost: 02:57/02:01 [32:30/5:14:50]  Acc_iter 15400       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:13:58,593   INFO  Train:   17/80 ( 21%) [ 601/928 ( 65%)]  Loss: 0.5614 (0.516)  LR: 1.736e-03  Time cost: 03:13/01:44 [32:46/5:14:29]  Acc_iter 15450       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:13:58,595   INFO  
2025-03-16 09:14:14,357   INFO  Train:   17/80 ( 21%) [ 651/928 ( 70%)]  Loss: 0.4914 (0.518)  LR: 1.743e-03  Time cost: 03:28/01:28 [33:02/5:13:47]  Acc_iter 15500       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:14:30,142   INFO  Train:   17/80 ( 21%) [ 701/928 ( 76%)]  Loss: 0.5412 (0.518)  LR: 1.750e-03  Time cost: 03:44/01:12 [33:18/5:13:11]  Acc_iter 15550       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:14:46,028   INFO  Train:   17/80 ( 21%) [ 751/928 ( 81%)]  Loss: 0.3788 (0.517)  LR: 1.757e-03  Time cost: 04:00/00:56 [33:34/5:12:46]  Acc_iter 15600       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:14:46,030   INFO  
2025-03-16 09:15:01,848   INFO  Train:   17/80 ( 21%) [ 801/928 ( 86%)]  Loss: 0.5713 (0.516)  LR: 1.764e-03  Time cost: 04:16/00:40 [33:49/5:12:16]  Acc_iter 15650       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:15:17,776   INFO  Train:   17/80 ( 21%) [ 851/928 ( 92%)]  Loss: 0.5152 (0.516)  LR: 1.771e-03  Time cost: 04:32/00:24 [34:05/5:11:56]  Acc_iter 15700       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:15:33,748   INFO  Train:   17/80 ( 21%) [ 901/928 ( 97%)]  Loss: 0.5071 (0.517)  LR: 1.778e-03  Time cost: 04:48/00:08 [34:21/5:11:39]  Acc_iter 15750       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:15:33,749   INFO  
2025-03-16 09:15:41,840   INFO  Train:   17/80 ( 21%) [ 927/928 (100%)]  Loss: 0.4923 (0.517)  LR: 1.782e-03  Time cost: 04:56/00:00 [34:29/5:11:17]  Acc_iter 15776       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:15:43,210   INFO  Train:   18/80 ( 22%) [   0/928 (  0%)]  Loss: 0.4395 (0.440)  LR: 1.782e-03  Time cost: 00:00/13:38 [34:31/14:19:11]  Acc_iter 15777       Data time: 0.51(0.51)  Forward time: 0.36(0.36)  Batch time: 0.87(0.87)
2025-03-16 09:15:50,557   INFO  Train:   18/80 ( 22%) [  23/928 (  2%)]  Loss: 0.4716 (0.497)  LR: 1.786e-03  Time cost: 00:08/05:10 [34:38/5:33:56]  Acc_iter 15800       Data time: 0.02(0.04)  Forward time: 0.29(0.31)  Batch time: 0.31(0.34)
2025-03-16 09:16:06,344   INFO  Train:   18/80 ( 22%) [  73/928 (  8%)]  Loss: 0.4998 (0.506)  LR: 1.793e-03  Time cost: 00:24/04:37 [34:54/5:15:50]  Acc_iter 15850       Data time: 0.01(0.02)  Forward time: 0.32(0.30)  Batch time: 0.33(0.32)
2025-03-16 09:16:22,189   INFO  Train:   18/80 ( 22%) [ 123/928 ( 13%)]  Loss: 0.5772 (0.514)  LR: 1.800e-03  Time cost: 00:39/04:18 [35:10/5:12:33]  Acc_iter 15900       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:16:22,191   INFO  
2025-03-16 09:16:38,075   INFO  Train:   18/80 ( 22%) [ 173/928 ( 19%)]  Loss: 0.4881 (0.513)  LR: 1.807e-03  Time cost: 00:55/04:01 [35:26/5:11:15]  Acc_iter 15950       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:16:54,057   INFO  Train:   18/80 ( 22%) [ 223/928 ( 24%)]  Loss: 0.5858 (0.514)  LR: 1.814e-03  Time cost: 01:11/03:45 [35:42/5:10:49]  Acc_iter 16000       Data time: 0.02(0.02)  Forward time: 0.33(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:17:10,052   INFO  Train:   18/80 ( 22%) [ 273/928 ( 29%)]  Loss: 0.4925 (0.515)  LR: 1.821e-03  Time cost: 01:27/03:29 [35:58/5:10:30]  Acc_iter 16050       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:17:10,054   INFO  
2025-03-16 09:17:25,961   INFO  Train:   18/80 ( 22%) [ 323/928 ( 35%)]  Loss: 0.5064 (0.515)  LR: 1.828e-03  Time cost: 01:43/03:13 [36:14/5:09:56]  Acc_iter 16100       Data time: 0.02(0.02)  Forward time: 0.28(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:17:41,856   INFO  Train:   18/80 ( 22%) [ 373/928 ( 40%)]  Loss: 0.5639 (0.514)  LR: 1.835e-03  Time cost: 01:59/02:57 [36:29/5:09:25]  Acc_iter 16150       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:17:57,800   INFO  Train:   18/80 ( 22%) [ 423/928 ( 46%)]  Loss: 0.5598 (0.514)  LR: 1.842e-03  Time cost: 02:15/02:41 [36:45/5:09:04]  Acc_iter 16200       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:17:57,801   INFO  
2025-03-16 09:18:13,705   INFO  Train:   18/80 ( 22%) [ 473/928 ( 51%)]  Loss: 0.5152 (0.515)  LR: 1.849e-03  Time cost: 02:31/02:25 [37:01/5:08:39]  Acc_iter 16250       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:18:29,606   INFO  Train:   18/80 ( 22%) [ 523/928 ( 56%)]  Loss: 0.4878 (0.516)  LR: 1.856e-03  Time cost: 02:47/02:09 [37:17/5:08:16]  Acc_iter 16300       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:18:45,520   INFO  Train:   18/80 ( 22%) [ 573/928 ( 62%)]  Loss: 0.4361 (0.516)  LR: 1.863e-03  Time cost: 03:03/01:53 [37:33/5:07:55]  Acc_iter 16350       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:18:45,522   INFO  
2025-03-16 09:19:01,384   INFO  Train:   18/80 ( 22%) [ 623/928 ( 67%)]  Loss: 0.4577 (0.516)  LR: 1.871e-03  Time cost: 03:19/01:37 [37:49/5:07:31]  Acc_iter 16400       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:19:17,245   INFO  Train:   18/80 ( 22%) [ 673/928 ( 73%)]  Loss: 0.5526 (0.516)  LR: 1.878e-03  Time cost: 03:34/01:21 [38:05/5:07:07]  Acc_iter 16450       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:19:33,284   INFO  Train:   18/80 ( 22%) [ 723/928 ( 78%)]  Loss: 0.4808 (0.517)  LR: 1.885e-03  Time cost: 03:50/01:05 [38:21/5:06:59]  Acc_iter 16500       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:19:33,287   INFO  
2025-03-16 09:19:49,211   INFO  Train:   18/80 ( 22%) [ 773/928 ( 83%)]  Loss: 0.5447 (0.516)  LR: 1.892e-03  Time cost: 04:06/00:49 [38:37/5:06:41]  Acc_iter 16550       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:20:05,167   INFO  Train:   18/80 ( 22%) [ 823/928 ( 89%)]  Loss: 0.6371 (0.516)  LR: 1.899e-03  Time cost: 04:22/00:33 [38:53/5:06:26]  Acc_iter 16600       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:20:21,136   INFO  Train:   18/80 ( 22%) [ 873/928 ( 94%)]  Loss: 0.5074 (0.516)  LR: 1.906e-03  Time cost: 04:38/00:17 [39:09/5:06:11]  Acc_iter 16650       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:20:21,138   INFO  
2025-03-16 09:20:36,996   INFO  Train:   18/80 ( 22%) [ 923/928 ( 99%)]  Loss: 0.4723 (0.515)  LR: 1.913e-03  Time cost: 04:54/00:01 [39:25/5:05:50]  Acc_iter 16700       Data time: 0.01(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:20:38,196   INFO  Train:   18/80 ( 22%) [ 927/928 (100%)]  Loss: 0.5010 (0.515)  LR: 1.913e-03  Time cost: 04:55/00:00 [39:26/5:05:44]  Acc_iter 16704       Data time: 0.02(0.02)  Forward time: 0.29(0.30)  Batch time: 0.30(0.32)
2025-03-16 09:20:39,525   INFO  Train:   19/80 ( 24%) [   0/928 (  0%)]  Loss: 0.4654 (0.465)  LR: 1.913e-03  Time cost: 00:00/12:50 [39:27/13:15:53]  Acc_iter 16705       Data time: 0.50(0.50)  Forward time: 0.32(0.32)  Batch time: 0.82(0.82)
2025-03-16 09:20:53,841   INFO  Train:   19/80 ( 24%) [  45/928 (  5%)]  Loss: 0.4558 (0.525)  LR: 1.920e-03  Time cost: 00:15/04:50 [39:41/5:15:29]  Acc_iter 16750       Data time: 0.02(0.03)  Forward time: 0.30(0.30)  Batch time: 0.32(0.33)
2025-03-16 09:21:09,812   INFO  Train:   19/80 ( 24%) [  95/928 ( 10%)]  Loss: 0.6388 (0.525)  LR: 1.927e-03  Time cost: 00:31/04:30 [39:57/5:10:18]  Acc_iter 16800       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:21:09,814   INFO  
2025-03-16 09:21:25,643   INFO  Train:   19/80 ( 24%) [ 145/928 ( 16%)]  Loss: 0.5948 (0.522)  LR: 1.934e-03  Time cost: 00:46/04:11 [40:13/5:07:34]  Acc_iter 16850       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:21:41,471   INFO  Train:   19/80 ( 24%) [ 195/928 ( 21%)]  Loss: 0.5358 (0.520)  LR: 1.941e-03  Time cost: 01:02/03:54 [40:29/5:06:05]  Acc_iter 16900       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.31(0.32)
2025-03-16 09:21:57,418   INFO  Train:   19/80 ( 24%) [ 245/928 ( 26%)]  Loss: 0.5397 (0.519)  LR: 1.948e-03  Time cost: 01:18/03:38 [40:45/5:05:33]  Acc_iter 16950       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:21:57,420   INFO  
2025-03-16 09:22:13,353   INFO  Train:   19/80 ( 24%) [ 295/928 ( 32%)]  Loss: 0.4731 (0.518)  LR: 1.955e-03  Time cost: 01:34/03:22 [41:01/5:05:05]  Acc_iter 17000       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:22:29,216   INFO  Train:   19/80 ( 24%) [ 345/928 ( 37%)]  Loss: 0.4471 (0.518)  LR: 1.962e-03  Time cost: 01:50/03:06 [41:17/5:04:28]  Acc_iter 17050       Data time: 0.02(0.02)  Forward time: 0.32(0.30)  Batch time: 0.34(0.32)
2025-03-16 09:22:45,095   INFO  Train:   19/80 ( 24%) [ 395/928 ( 43%)]  Loss: 0.5315 (0.519)  LR: 1.968e-03  Time cost: 02:06/02:50 [41:33/5:03:58]  Acc_iter 17100       Data time: 0.02(0.02)  Forward time: 0.30(0.30)  Batch time: 0.32(0.32)
2025-03-16 09:22:45,097   INFO  
